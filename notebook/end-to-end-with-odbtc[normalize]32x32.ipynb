{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Importing Library...\n",
      "Importing Library Success\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"Importing Library...\")\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data as putils\n",
    "\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets,transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import numpy\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "print(\"Importing Library Success\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% importing library\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Creating Class...\nCreating Class Success\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"Creating Class...\")\n",
    "\n",
    "class Codec():\n",
    "    def __init__(self, size, interpolate_size, mode):\n",
    "        self.size = size\n",
    "        self.interpolate_size = interpolate_size\n",
    "        self.mode = mode\n",
    "\n",
    "    def btc(self, image):\n",
    "        if image.shape[0] % self.size != 0:\n",
    "            n = ((self.size * int(image.shape[0] / self.size)) + self.size) - image.shape[0]\n",
    "            image = numpy.pad(array=image, pad_width=(0, n))\n",
    "\n",
    "        x = image.shape[0] / self.size\n",
    "        y = image.shape[1] / self.size\n",
    "        block_image = numpy.split(numpy.concatenate(numpy.split(image, y, axis=1)), x * y)\n",
    "        for i in range(len(block_image)):\n",
    "            mean = numpy.mean(numpy.mean(block_image[i], axis=1))\n",
    "            std = numpy.std(block_image[i])\n",
    "            m = self.size * self.size\n",
    "            q = numpy.sum(block_image[i] > mean)\n",
    "\n",
    "            a = mean - std * numpy.sqrt(q / (m - q))\n",
    "            b = mean + std * numpy.sqrt((m - q) / q)\n",
    "\n",
    "            block_image[i][block_image[i] > mean] = b\n",
    "            block_image[i][block_image[i] < mean] = a\n",
    "\n",
    "        block_image = numpy.concatenate(block_image)\n",
    "        block_image = numpy.split(block_image, x)\n",
    "\n",
    "        temp = numpy.concatenate(block_image, axis=1)\n",
    "\n",
    "        if image.shape[0] % self.size != 0:\n",
    "            temp = temp[1:-n + 1, 1:-n + 1]\n",
    "\n",
    "        return torch.Tensor(temp)\n",
    "\n",
    "    def BlockTruncationCoding(self, images_tensor):\n",
    "        results_tensor = images_tensor.new_empty(size=images_tensor.size())\n",
    "        for i in range(len(images_tensor)):\n",
    "            compact_image = images_tensor[i][0]\n",
    "            compressed_image = self.btc(compact_image)\n",
    "            results_tensor[i][0] = compressed_image\n",
    "        return results_tensor\n",
    "\n",
    "    def Interpolate(self, image):\n",
    "        return nn.functional.interpolate(input=image, scale_factor=self.interpolate_size, mode=self.mode,\n",
    "                                         align_corners=False)\n",
    "    \n",
    "\n",
    "class ODBTC():\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.ditherMatrix = self.bayer(size)\n",
    "        max = np.max(self.ditherMatrix)\n",
    "        min = np.min(self.ditherMatrix)\n",
    "        self.ditherMatrix = (self.ditherMatrix - min) / (max - min)\n",
    "\n",
    "    def rgb2grayscale(self, image):\n",
    "        temp = image[0, :, :] * 0.2989 + image[1, :, :] * 0.587 + image[2, :, :] * 0.114\n",
    "        temp = temp\n",
    "        return temp\n",
    "\n",
    "    def bayer(self, normalize=True):\n",
    "        matrix = self._bayer(0, 0, self.size, 0, 1)\n",
    "        return matrix / (self.size * self.size) \\\n",
    "            if normalize else matrix\n",
    "\n",
    "    def _bayer(self, x, y, size, value, step, matrix=None):\n",
    "        if matrix is None:\n",
    "            matrix = np.zeros((size, size))\n",
    "        if (size == 1):\n",
    "            matrix[y][x] = value\n",
    "            return\n",
    "\n",
    "        half = size // 2\n",
    "        self._bayer(x, y, half, value + (step * 0), step * 4, matrix)\n",
    "        self._bayer(x + half, y + half, half, value + (step * 1), step * 4, matrix)\n",
    "        self._bayer(x + half, y, half, value + (step * 2), step * 4, matrix)\n",
    "        self._bayer(x, y + half, half, value + (step * 3), step * 4, matrix)\n",
    "        return matrix\n",
    "\n",
    "    def calculate_single(self, image):\n",
    "        grayscaleImage = self.rgb2grayscale(image)\n",
    "        for i in range(len(image)):\n",
    "            image[i] = self.filter(image[i], i, grayscaleImage)\n",
    "\n",
    "        return image\n",
    "    \n",
    "    def __call__(self,image_batch):\n",
    "        for i in range(len(image_batch)):\n",
    "            image_batch[i] = self.calculate_single(image_batch[i])\n",
    "        \n",
    "        return image_batch\n",
    "        \n",
    "    def filter(self, image_channel, c, gs):\n",
    "        x = image_channel.shape[0] / self.size\n",
    "        y = image_channel.shape[1] / self.size\n",
    "        block_image = numpy.split(numpy.concatenate(numpy.split(image_channel, y, axis=1)), x * y)\n",
    "        block_image_gs = numpy.split(numpy.concatenate(numpy.split(gs, y, axis=1)), x * y)\n",
    "        for i in range(len(block_image)):\n",
    "            min = np.min(block_image[i])\n",
    "            max = np.max(block_image[i])\n",
    "\n",
    "            gsMin = np.min(block_image_gs[i])\n",
    "\n",
    "            k = max - min\n",
    "\n",
    "            temp = self.ditherMatrix.copy()\n",
    "\n",
    "            d = (temp * k) + gsMin\n",
    "\n",
    "            block_image[i][block_image[i] >= d] = max\n",
    "            block_image[i][block_image[i] < d] = min\n",
    "\n",
    "        block_image = numpy.concatenate(block_image)\n",
    "        block_image = numpy.split(block_image, x)\n",
    "\n",
    "        temp_last = numpy.concatenate(block_image, axis=1)\n",
    "\n",
    "        return torch.FloatTensor(temp_last)\n",
    "    \n",
    "\n",
    "class RecCNN(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(RecCNN, self).__init__()\n",
    "        self.deconv1 = nn.Conv2d(channel, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64, affine=False)\n",
    "        self.deconv_n = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn_n = nn.BatchNorm2d(64, affine=False)\n",
    "        self.deconv3 = nn.ConvTranspose2d(64, channel, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.deconv1(x))\n",
    "        for _ in range(18):\n",
    "            out = self.relu(self.bn_n(self.deconv_n(out)))\n",
    "        out = self.deconv3(out)\n",
    "        final = out.add(x)\n",
    "        return final, out\n",
    "class ComCNN(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(ComCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channel, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64, affine=False)\n",
    "        self.conv3 = nn.Conv2d(64, channel, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.relu(self.bn1(self.conv2(out)))\n",
    "        return self.conv3(out)\n",
    "\n",
    "\n",
    "def loss_function_l1(reconstructed_image,original_image):\n",
    "    return nn.MSELoss(size_average=False)(reconstructed_image,original_image)\n",
    "\n",
    "def loss_function_l2(residual_image,decoded_image,original_image):\n",
    "    return nn.MSELoss(size_average=False)(residual_image,original_image-decoded_image)\n",
    "\n",
    "def psnr(img1, img2):\n",
    "    mse = numpy.mean( (img1 - img2) ** 2 )\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 255.0\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "import math\n",
    "irange = range\n",
    "\n",
    "\n",
    "def make_grid(tensor, nrow=8, padding=2,\n",
    "              normalize=False, range=None, scale_each=False, pad_value=0):\n",
    "    \"\"\"Make a grid of images.\n",
    "    Args:\n",
    "        tensor (Tensor or list): 4D mini-batch Tensor of shape (B x C x H x W)\n",
    "            or a list of images all of the same size.\n",
    "        nrow (int, optional): Number of images displayed in each row of the grid.\n",
    "            The Final grid size is (B / nrow, nrow). Default is 8.\n",
    "        padding (int, optional): amount of padding. Default is 2.\n",
    "        normalize (bool, optional): If True, shift the image to the range (0, 1),\n",
    "            by subtracting the minimum and dividing by the maximum pixel value.\n",
    "        range (tuple, optional): tuple (min, max) where min and max are numbers,\n",
    "            then these numbers are used to normalize the image. By default, min and max\n",
    "            are computed from the tensor.\n",
    "        scale_each (bool, optional): If True, scale each image in the batch of\n",
    "            images separately rather than the (min, max) over all images.\n",
    "        pad_value (float, optional): Value for the padded pixels.\n",
    "    Example:\n",
    "        See this notebook `here <https://gist.github.com/anonymous/bf16430f7750c023141c562f3e9f2a91>`_\n",
    "    \"\"\"\n",
    "    if not (torch.is_tensor(tensor) or\n",
    "            (isinstance(tensor, list) and all(torch.is_tensor(t) for t in tensor))):\n",
    "        raise TypeError('tensor or list of tensors expected, got {}'.format(type(tensor)))\n",
    "\n",
    "    # if list of tensors, convert to a 4D mini-batch Tensor\n",
    "    if isinstance(tensor, list):\n",
    "        tensor = torch.stack(tensor, dim=0)\n",
    "\n",
    "    if tensor.dim() == 2:  # single image H x W\n",
    "        tensor = tensor.view(1, tensor.size(0), tensor.size(1))\n",
    "    if tensor.dim() == 3:  # single image\n",
    "        if tensor.size(0) == 1:  # if single-channel, convert to 3-channel\n",
    "            tensor = torch.cat((tensor, tensor, tensor), 0)\n",
    "        tensor = tensor.view(1, tensor.size(0), tensor.size(1), tensor.size(2))\n",
    "\n",
    "    if tensor.dim() == 4 and tensor.size(1) == 1:  # single-channel images\n",
    "        tensor = torch.cat((tensor, tensor, tensor), 1)\n",
    "\n",
    "    if normalize is True:\n",
    "        tensor = tensor.clone()  # avoid modifying tensor in-place\n",
    "        if range is not None:\n",
    "            assert isinstance(range, tuple), \\\n",
    "                \"range has to be a tuple (min, max) if specified. min and max are numbers\"\n",
    "\n",
    "        def norm_ip(img, min, max):\n",
    "            img.clamp_(min=min, max=max)\n",
    "            img.add_(-min).div_(max - min + 1e-5)\n",
    "\n",
    "        def norm_range(t, range):\n",
    "            if range is not None:\n",
    "                norm_ip(t, range[0], range[1])\n",
    "            else:\n",
    "                norm_ip(t, float(t.min()), float(t.max()))\n",
    "\n",
    "        if scale_each is True:\n",
    "            for t in tensor:  # loop over mini-batch dimension\n",
    "                norm_range(t, range)\n",
    "        else:\n",
    "            norm_range(tensor, range)\n",
    "\n",
    "    if tensor.size(0) == 1:\n",
    "        return tensor.squeeze()\n",
    "\n",
    "    # make the mini-batch of images into a grid\n",
    "    nmaps = tensor.size(0)\n",
    "    xmaps = min(nrow, nmaps)\n",
    "    ymaps = int(math.ceil(float(nmaps) / xmaps))\n",
    "    height, width = int(tensor.size(2) + padding), int(tensor.size(3) + padding)\n",
    "    grid = tensor.new(3, height * ymaps + padding, width * xmaps + padding).fill_(pad_value)\n",
    "    k = 0\n",
    "    for y in irange(ymaps):\n",
    "        for x in irange(xmaps):\n",
    "            if k >= nmaps:\n",
    "                break\n",
    "            grid.narrow(1, y * height + padding, height - padding)\\\n",
    "                .narrow(2, x * width + padding, width - padding)\\\n",
    "                .copy_(tensor[k])\n",
    "            k = k + 1\n",
    "    return grid\n",
    "\n",
    "\n",
    "def save_image(tensor, filename, nrow=8, padding=2,\n",
    "               normalize=False, range=None, scale_each=False, pad_value=0):\n",
    "    \"\"\"Save a given Tensor into an image file.\n",
    "    Args:\n",
    "        tensor (Tensor or list): Image to be saved. If given a mini-batch tensor,\n",
    "            saves the tensor as a grid of images by calling ``make_grid``.\n",
    "        **kwargs: Other arguments are documented in ``make_grid``.\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "    grid = make_grid(tensor, nrow=nrow, padding=padding, pad_value=pad_value,\n",
    "                     normalize=normalize, range=range, scale_each=scale_each)\n",
    "    ndarr = grid.mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()\n",
    "    im = Image.fromarray(ndarr)\n",
    "    im.save(filename)\n",
    "\n",
    "\n",
    "print(\"Creating Class Success\")\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Create Class\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Load Image Dataset\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Load Image Dataset Success\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"Load Image Dataset\")\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.24703223,  0.24348513 , 0.26158784))\n",
    "])\n",
    "\n",
    "train_set = datasets.CIFAR10(root='./cifar-10-batches-py',train=True,download=True,transform=image_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = datasets.CIFAR10(root='./cifar-10-batches-py',train=False,download=True,transform=image_transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_set,batch_size=64,\n",
    "                                          shuffle=True,num_workers=2)\n",
    "\n",
    "print(\"Load Image Dataset Success\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Prepared Dataset\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Initialize Model....\n",
      "Cuda is available, using gpu instead\nInitialize Model Success\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"Initialize Model....\")\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "codec = Codec(4,2,'bicubic')\n",
    "odbtc = ODBTC(4)\n",
    "\n",
    "if CUDA:\n",
    "    comCNN = ComCNN(3).cuda()\n",
    "    recCNN = RecCNN(3).cuda()\n",
    "    print(\"Cuda is available, using gpu instead\")\n",
    "else:\n",
    "    comCNN = ComCNN(3)\n",
    "    recCNN = RecCNN(3)\n",
    "    print(\"Cuda is not available, using cpu instead\")\n",
    "\n",
    "comCNNOptimizer = optim.Adam(comCNN.parameters(),lr=1e-3)\n",
    "\n",
    "recCNNOptimizer = optim.Adam(recCNN.parameters(),lr=1e-3)\n",
    "\n",
    "print(\"Initialize Model Success\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Create a model\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Begin Training....\n",
      "====> Epoch: 0\nAverage loss 1: 1914872.6922\nAverage Loss 2: 1034235.0263\nRunning Time : 400.02381324768066\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "d:\\pycharmprojects\\end-to-end-compression-framework\\venv\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n  warnings.warn(warning.format(ret))\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-9108bfa912cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mloss2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mtrain_loss_2\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mrecCNNOptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "import time\n",
    "print(\"Begin Training....\")\n",
    "epochs = 10\n",
    "comCNN.train()\n",
    "recCNN.train()\n",
    "graph_l1 = np.empty(epochs)\n",
    "graph_l2 = np.empty(epochs)\n",
    "global_start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    train_loss_1 = 0\n",
    "    train_loss_2 = 0\n",
    "    for batch_idx,(data,_) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        \n",
    "        compact_image = comCNN(data.cuda())\n",
    "        \n",
    "        compact_image_temp = compact_image.cpu().detach()\n",
    "        \n",
    "        # compressed_image_btc = codec.BlockTruncationCoding(compact_image_temp)\n",
    "        compressed_image_odbtc = odbtc(compact_image_temp)\n",
    "        upscaled_image_btc = codec.Interpolate(compressed_image_odbtc)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # update beta with eq 5\n",
    "    \n",
    "        recCNNOptimizer.zero_grad()\n",
    "        reconstructed_image,residual = recCNN(upscaled_image_btc.cuda())\n",
    "        loss2 = loss_function_l2(\n",
    "            residual_image=residual,\n",
    "            decoded_image=upscaled_image_btc.cuda(),\n",
    "            original_image=data.cuda()\n",
    "        )\n",
    "        loss2.backward()\n",
    "        \n",
    "        train_loss_2 += loss2.item()\n",
    "        recCNNOptimizer.step()\n",
    "    \n",
    "    \n",
    "        comCNNOptimizer.zero_grad()\n",
    "        upscaled_image_nonbtc = codec.Interpolate(compact_image)\n",
    "        reconstructed_without_btc,_ = recCNN(upscaled_image_nonbtc.cuda())\n",
    "        loss1 = loss_function_l1(\n",
    "            reconstructed_image=reconstructed_without_btc.cuda(),\n",
    "            original_image=data.cuda()\n",
    "        )\n",
    "        loss1.backward()\n",
    "        train_loss_1 += loss1.item()\n",
    "        comCNNOptimizer.step()\n",
    "        # print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} - {:.6f}'.format(\n",
    "        #         epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        #         100. * batch_idx / len(train_loader),\n",
    "        #         loss1.item() / len(data) , loss2.item()/len(data)))\n",
    "    end = time.time()\n",
    "    graph_l1[epoch] = train_loss_1/len(train_loader.dataset)\n",
    "    graph_l2[epoch] = train_loss_2/len(train_loader.dataset)\n",
    "    print('====> Epoch: {}\\nAverage loss 1: {:.4f}\\nAverage Loss 2: {:.4f}\\nRunning Time : {}'.format(\n",
    "          epoch, train_loss_1/len(train_loader.dataset),train_loss_2/len(train_loader.dataset),(end-start)))\n",
    "\n",
    "global_end = time.time()\n",
    "print(\"\\n========>Training Complete....\")\n",
    "print('Total Running Time : {}'.format((global_end-global_start)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Train\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Saving Model...\n",
      "Model saved\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "d:\\pycharmprojects\\end-to-end-compression-framework\\venv\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type ComCNN. It won't be checked for correctness upon loading.\n  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "d:\\pycharmprojects\\end-to-end-compression-framework\\venv\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RecCNN. It won't be checked for correctness upon loading.\n  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"Saving Model...\")\n",
    "torch.save(comCNN,'../model/ComCNN-with-odbtc[normalize]32x32.pt')\n",
    "torch.save(recCNN,'../model/RecCNN-with-odbtc[normalize]32x32.pt')\n",
    "print(\"Model saved\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Saving Model\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.plot(graph_l1)\n",
    "plt.title(\"MSE L1\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(graph_l2)\n",
    "plt.title('MSE L2')\n",
    "plt.grid(True)\n",
    "plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25,\n",
    "                    wspace=0.35)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% create graph\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Load trained model...\nLoad success\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"Load trained model...\")\n",
    "trainedComCNN = torch.load('../model/ComCNN-with-odbtc[normalize]32x32.pt')\n",
    "trainedRecCNN = torch.load('../model/RecCNN-with-odbtc[normalize]32x32.pt')\n",
    "# codec = Codec(4,2,'bicubic')\n",
    "print(\"Load success\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Load Model\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Begin Testing....\n",
      "\n========>Teesting Complete....\nTotal Running Time : 212.17981219291687\nLoss Function ComCNN Average : 10273.4110609375\nLoss Function RecCNN Average : 10273.4110609375\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import time\n",
    "trainedComCNN.eval()\n",
    "trainedRecCNN.eval()\n",
    "print(\"Begin Testing....\")\n",
    "\n",
    "graph_l1_test = np.empty(len(test_loader.dataset))\n",
    "graph_l2_test = np.empty(len(test_loader.dataset))\n",
    "global_start = time.time()\n",
    "\n",
    "i = 0\n",
    "\n",
    "for batch_idx,(data,_) in enumerate(train_loader):\n",
    "    data = Variable(data)\n",
    "    compact_image = trainedComCNN(data.cuda())\n",
    "    compact_image_temp = compact_image.cpu().detach()\n",
    "    # compressed_image_btc = codec.BlockTruncationCoding(compact_image_temp)\n",
    "    compressed_image_odbtc = odbtc(compact_image_temp)\n",
    "    upscaled_image_btc = codec.Interpolate(compressed_image_odbtc)\n",
    "    \n",
    "    \n",
    "    reconstructed_image,residual = trainedRecCNN(upscaled_image_btc.cuda())\n",
    "    loss2 = loss_function_l2(\n",
    "            residual_image=residual,\n",
    "            decoded_image=upscaled_image_btc.cuda(),\n",
    "            original_image=data.cuda()\n",
    "        )\n",
    "    \n",
    "    upscaled_image_nonbtc = codec.Interpolate(compact_image)\n",
    "    reconstructed_without_btc,_ = trainedRecCNN(upscaled_image_nonbtc.cuda())\n",
    "    loss1 = loss_function_l1(\n",
    "            reconstructed_image=reconstructed_without_btc.cuda(),\n",
    "            original_image=data.cuda()\n",
    "        )\n",
    "    \n",
    "    graph_l1_test[i] = loss1.item()\n",
    "    \n",
    "    graph_l2_test[i] = loss2.item()\n",
    "    i+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "global_end = time.time()\n",
    "print(\"\\n========>Teesting Complete....\")\n",
    "print('Total Running Time : {}'.format((global_end-global_start)))\n",
    "print('Loss Function ComCNN Average : {}'.format(np.sum(graph_l1_test)/len(test_loader.dataset)))\n",
    "print('Loss Function RecCNN Average : {}'.format(np.sum(graph_l1_test)/len(test_loader.dataset)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Test Model\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c74a7ff1372a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpsnr_total\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcompact_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainedComCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "psnr_total = 0\n",
    "for batch_idx,(data,_) in enumerate(test_loader):\n",
    "    data = Variable(data)\n",
    "    \n",
    "    compact_image = trainedComCNN(data.cuda())\n",
    "    compact_image_temp = compact_image.cpu().detach()\n",
    "    # compressed_image_btc = codec.BlockTruncationCoding(compact_image_temp)\n",
    "    compressed_image_odbtc = odbtc(compact_image_temp)\n",
    "    upscaled_image_btc = codec.Interpolate(compressed_image_odbtc)\n",
    "    \n",
    "    \n",
    "    reconstructed_image,residual = trainedRecCNN(upscaled_image_btc.cuda())\n",
    "    \n",
    "    upscaled_image_nonbtc = codec.Interpolate(compact_image)\n",
    "    reconstructed_without_btc,_ = trainedRecCNN(upscaled_image_nonbtc.cuda())\n",
    "    \n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        img1 = reconstructed_image[i][0].cpu().detach().numpy()\n",
    "        img2 = data[i][0].cpu().detach().numpy()\n",
    "        psnr_temp = psnr(img1,img2)\n",
    "        print(\"Test Set {} -> psnr : {}\".format(i,psnr_temp))\n",
    "        psnr_total += psnr_temp\n",
    "        save_image(data[i],'../result/end-to-end-with-odbtc[normalize]32x32/ori-{}.png'.format(i))\n",
    "        save_image(reconstructed_image[i],'../result/end-to-end-with-odbtc[normalize]32x32/recon-{}.png'.format(i))\n",
    "    \n",
    "    save_image(data[:],'../result/end-to-end-with-odbtc[normalize]32x32/original.png')    \n",
    "    save_image(reconstructed_image[:],'../result/end-to-end-with-odbtc[normalize]32x32/recon.png')\n",
    "\n",
    "print(\"Average psnr : {}\".format(psnr_total/len(test_loader.dataset)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  Show Image\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}