{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% importing library\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Importing Library...\n",
      "Importing Library Success\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"Importing Library...\")\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data as putils\n",
    "\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets,transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import numpy\n",
    "import numpy as np\n",
    "\n",
    "print(\"Importing Library Success\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Creating Class...\nCreating Class Success\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"Creating Class...\")\n",
    "\n",
    "class Codec():\n",
    "    def __init__(self, size, interpolate_size, mode):\n",
    "        self.size = size\n",
    "        self.interpolate_size = interpolate_size\n",
    "        self.mode = mode\n",
    "\n",
    "    def btc(self, image):\n",
    "        if image.shape[0] % self.size != 0:\n",
    "            n = ((self.size * int(image.shape[0] / self.size)) + self.size) - image.shape[0]\n",
    "            image = numpy.pad(array=image, pad_width=(0, n))\n",
    "\n",
    "        x = image.shape[0] / self.size\n",
    "        y = image.shape[1] / self.size\n",
    "        block_image = numpy.split(numpy.concatenate(numpy.split(image, y, axis=1)), x * y)\n",
    "        for i in range(len(block_image)):\n",
    "            mean = numpy.mean(numpy.mean(block_image[i], axis=1))\n",
    "            std = numpy.std(block_image[i])\n",
    "            m = self.size * self.size\n",
    "            q = numpy.sum(block_image[i] > mean)\n",
    "\n",
    "            a = mean - std * numpy.sqrt(q / (m - q))\n",
    "            b = mean + std * numpy.sqrt((m - q) / q)\n",
    "\n",
    "            block_image[i][block_image[i] > mean] = b\n",
    "            block_image[i][block_image[i] < mean] = a\n",
    "\n",
    "        block_image = numpy.concatenate(block_image)\n",
    "        block_image = numpy.split(block_image, x)\n",
    "\n",
    "        temp = numpy.concatenate(block_image, axis=1)\n",
    "\n",
    "        if image.shape[0] % self.size != 0:\n",
    "            temp = temp[1:-n + 1, 1:-n + 1]\n",
    "\n",
    "        return torch.Tensor(temp)\n",
    "\n",
    "    def BlockTruncationCoding(self, images_tensor):\n",
    "        results_tensor = images_tensor.new_empty(size=images_tensor.size())\n",
    "        for i in range(len(images_tensor)):\n",
    "            compact_image = images_tensor[i][0]\n",
    "            compressed_image = self.btc(compact_image)\n",
    "            results_tensor[i][0] = compressed_image\n",
    "        return results_tensor\n",
    "\n",
    "    def Interpolate(self, image):\n",
    "        return nn.functional.interpolate(input=image, scale_factor=self.interpolate_size, mode=self.mode,\n",
    "                                         align_corners=False)\n",
    "\n",
    "class RecCNN(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(RecCNN, self).__init__()\n",
    "        self.deconv1 = nn.Conv2d(channel, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64, affine=False)\n",
    "        self.deconv_n = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn_n = nn.BatchNorm2d(64, affine=False)\n",
    "        self.deconv3 = nn.ConvTranspose2d(64, channel, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.deconv1(x))\n",
    "        for _ in range(18):\n",
    "            out = self.relu(self.bn_n(self.deconv_n(out)))\n",
    "        out = self.deconv3(out)\n",
    "        final = out.add(x)\n",
    "        return final, out\n",
    "class ComCNN(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(ComCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channel, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64, affine=False)\n",
    "        self.conv3 = nn.Conv2d(64, channel, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.relu(self.bn1(self.conv2(out)))\n",
    "        return self.conv3(out)\n",
    "\n",
    "\n",
    "def loss_function_l1(reconstructed_image,original_image):\n",
    "    return nn.MSELoss(size_average=False)(reconstructed_image,original_image)\n",
    "\n",
    "def loss_function_l2(residual_image,decoded_image,original_image):\n",
    "    return nn.MSELoss(size_average=False)(residual_image,original_image-decoded_image)\n",
    "\n",
    "print(\"Creating Class Success\")\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Create Class\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Load Image Dataset\nLoad Image Dataset Success\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"Load Image Dataset\")\n",
    "train_image_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(size=(64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((105.97411112882654,),(63.11390135470555,))\n",
    "])\n",
    "\n",
    "test_image_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(size=(64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((85.35398198341836,),(65.0054783896806,))\n",
    "])\n",
    "\n",
    "\n",
    "train_path = '../dataset/train/'\n",
    "test_path = '../dataset/test/'\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=train_path,\n",
    "    transform=train_image_transform\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=test_path,\n",
    "    transform=test_image_transform\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=32,\n",
    "                                          shuffle=True,num_workers=2)\n",
    "\n",
    "print(\"Load Image Dataset Success\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Prepared Dataset\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Initialize Model....\n",
      "Cuda is available, using gpu instead\nInitialize Model Success\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"Initialize Model....\")\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "codec = Codec(4,2,'bicubic')\n",
    "\n",
    "if CUDA:\n",
    "    comCNN = ComCNN(1).cuda()\n",
    "    recCNN = RecCNN(1).cuda()\n",
    "    print(\"Cuda is available, using gpu instead\")\n",
    "else:\n",
    "    comCNN = ComCNN(1)\n",
    "    recCNN = RecCNN(1)\n",
    "    print(\"Cuda is not available, using cpu instead\")\n",
    "\n",
    "comCNNOptimizer = optim.Adam(comCNN.parameters(),lr=1e-3)\n",
    "\n",
    "recCNNOptimizer = optim.Adam(recCNN.parameters(),lr=1e-3)\n",
    "\n",
    "print(\"Initialize Model Success\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Create a model\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Begin Training....\n",
      "====> Epoch: 0\nAverage loss 1: 14190.8648\nAverage Loss 2: 18831.0965\nRunning Time : 13.313406944274902\n",
      "====> Epoch: 1\nAverage loss 1: 1259.3524\nAverage Loss 2: 1331.8019\nRunning Time : 12.252245426177979\n",
      "====> Epoch: 2\nAverage loss 1: 497.5458\nAverage Loss 2: 517.9189\nRunning Time : 12.24825668334961\n",
      "====> Epoch: 3\nAverage loss 1: 215.1664\nAverage Loss 2: 236.0798\nRunning Time : 12.288150787353516\n",
      "====> Epoch: 4\nAverage loss 1: 123.8327\nAverage Loss 2: 146.0863\nRunning Time : 12.274187803268433\n",
      "====> Epoch: 5\nAverage loss 1: 93.2451\nAverage Loss 2: 105.7535\nRunning Time : 12.23130178451538\n",
      "====> Epoch: 6\nAverage loss 1: 73.7038\nAverage Loss 2: 84.7162\nRunning Time : 12.257331609725952\n",
      "====> Epoch: 7\nAverage loss 1: 61.1188\nAverage Loss 2: 71.0148\nRunning Time : 12.255293846130371\n",
      "====> Epoch: 8\nAverage loss 1: 52.4816\nAverage Loss 2: 60.3815\nRunning Time : 12.285191297531128\n",
      "====> Epoch: 9\nAverage loss 1: 45.3563\nAverage Loss 2: 61.0128\nRunning Time : 12.216341018676758\n",
      "====> Epoch: 10\nAverage loss 1: 40.1864\nAverage Loss 2: 52.4333\nRunning Time : 12.23133659362793\n",
      "====> Epoch: 11\nAverage loss 1: 35.2672\nAverage Loss 2: 40.4979\nRunning Time : 12.235339164733887\n",
      "====> Epoch: 12\nAverage loss 1: 32.4795\nAverage Loss 2: 34.7511\nRunning Time : 12.256289958953857\n",
      "====> Epoch: 13\nAverage loss 1: 29.8752\nAverage Loss 2: 29.6650\nRunning Time : 12.261252164840698\n",
      "====> Epoch: 14\nAverage loss 1: 27.0563\nAverage Loss 2: 26.1411\nRunning Time : 12.226446390151978\n",
      "====> Epoch: 15\nAverage loss 1: 25.2298\nAverage Loss 2: 23.6973\nRunning Time : 12.281201124191284\n",
      "====> Epoch: 16\nAverage loss 1: 23.4634\nAverage Loss 2: 21.4320\nRunning Time : 12.351979494094849\n",
      "====> Epoch: 17\nAverage loss 1: 21.9037\nAverage Loss 2: 19.1894\nRunning Time : 12.270198345184326\n",
      "====> Epoch: 18\nAverage loss 1: 20.7011\nAverage Loss 2: 17.2104\nRunning Time : 12.267366170883179\n",
      "====> Epoch: 19\nAverage loss 1: 19.2918\nAverage Loss 2: 15.8019\nRunning Time : 12.287224769592285\n",
      "====> Epoch: 20\nAverage loss 1: 18.0145\nAverage Loss 2: 14.4400\nRunning Time : 12.271900415420532\n",
      "====> Epoch: 21\nAverage loss 1: 16.8410\nAverage Loss 2: 13.0672\nRunning Time : 12.27219271659851\n",
      "====> Epoch: 22\nAverage loss 1: 15.6892\nAverage Loss 2: 11.6905\nRunning Time : 12.262295007705688\n",
      "====> Epoch: 23\nAverage loss 1: 14.7200\nAverage Loss 2: 10.4452\nRunning Time : 12.388097763061523\n",
      "====> Epoch: 24\nAverage loss 1: 13.8682\nAverage Loss 2: 9.5121\nRunning Time : 12.434758186340332\n",
      "====> Epoch: 25\nAverage loss 1: 12.9636\nAverage Loss 2: 8.7145\nRunning Time : 12.378908634185791\n",
      "====> Epoch: 26\nAverage loss 1: 12.0449\nAverage Loss 2: 7.9940\nRunning Time : 12.502575874328613\n",
      "====> Epoch: 27\nAverage loss 1: 11.2963\nAverage Loss 2: 7.3915\nRunning Time : 12.381897449493408\n",
      "====> Epoch: 28\nAverage loss 1: 10.5247\nAverage Loss 2: 6.9098\nRunning Time : 12.385889530181885\n",
      "====> Epoch: 29\nAverage loss 1: 9.8271\nAverage Loss 2: 6.5005\nRunning Time : 12.435863733291626\n",
      "====> Epoch: 30\nAverage loss 1: 9.1317\nAverage Loss 2: 6.1481\nRunning Time : 12.26724123954773\n",
      "====> Epoch: 31\nAverage loss 1: 8.5305\nAverage Loss 2: 5.8936\nRunning Time : 12.257303714752197\n",
      "====> Epoch: 32\nAverage loss 1: 8.0469\nAverage Loss 2: 5.7591\nRunning Time : 12.427774429321289\n",
      "====> Epoch: 33\nAverage loss 1: 7.4581\nAverage Loss 2: 5.4834\nRunning Time : 12.344069957733154\n",
      "====> Epoch: 34\nAverage loss 1: 6.8571\nAverage Loss 2: 5.0806\nRunning Time : 12.24336552619934\n",
      "====> Epoch: 35\nAverage loss 1: 6.3603\nAverage Loss 2: 4.7360\nRunning Time : 12.409899711608887\n",
      "====> Epoch: 36\nAverage loss 1: 5.9295\nAverage Loss 2: 4.4356\nRunning Time : 12.381004333496094\n",
      "====> Epoch: 37\nAverage loss 1: 5.5677\nAverage Loss 2: 4.2157\nRunning Time : 12.315078258514404\n",
      "====> Epoch: 38\nAverage loss 1: 5.2578\nAverage Loss 2: 4.0273\nRunning Time : 12.337089538574219\n",
      "====> Epoch: 39\nAverage loss 1: 4.9734\nAverage Loss 2: 3.8352\nRunning Time : 12.293171167373657\n",
      "====> Epoch: 40\nAverage loss 1: 4.7081\nAverage Loss 2: 3.7344\nRunning Time : 12.439744710922241\n",
      "====> Epoch: 41\nAverage loss 1: 4.4797\nAverage Loss 2: 3.7144\nRunning Time : 12.321195840835571\n",
      "====> Epoch: 42\nAverage loss 1: 4.2482\nAverage Loss 2: 3.5313\nRunning Time : 12.42385482788086\n",
      "====> Epoch: 43\nAverage loss 1: 4.0467\nAverage Loss 2: 3.3649\nRunning Time : 12.250320196151733\n",
      "====> Epoch: 44\nAverage loss 1: 3.8452\nAverage Loss 2: 3.2095\nRunning Time : 12.337019443511963\n",
      "====> Epoch: 45\nAverage loss 1: 3.6641\nAverage Loss 2: 3.0604\nRunning Time : 12.288150072097778\n",
      "====> Epoch: 46\nAverage loss 1: 3.5244\nAverage Loss 2: 2.9388\nRunning Time : 12.35197925567627\n",
      "====> Epoch: 47\nAverage loss 1: 3.3932\nAverage Loss 2: 2.8219\nRunning Time : 12.298122644424438\n",
      "====> Epoch: 48\nAverage loss 1: 3.2768\nAverage Loss 2: 2.6875\nRunning Time : 12.454739809036255\n",
      "====> Epoch: 49\nAverage loss 1: 3.1758\nAverage Loss 2: 2.5621\nRunning Time : 12.39486575126648\n\n========>Training Complete....\nTotal Running Time : 616.8534979820251\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "d:\\pycharmprojects\\end-to-end-compression-framework\\venv\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n  warnings.warn(warning.format(ret))\n",
      "d:\\pycharmprojects\\end-to-end-compression-framework\\venv\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: divide by zero encountered in long_scalars\nd:\\pycharmprojects\\end-to-end-compression-framework\\venv\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in multiply\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import time\n",
    "print(\"Begin Training....\")\n",
    "epochs = 50\n",
    "comCNN.train()\n",
    "recCNN.train()\n",
    "graph_l1 = np.empty(epochs)\n",
    "graph_l2 = np.empty(epochs)\n",
    "global_start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    train_loss_1 = 0\n",
    "    train_loss_2 = 0\n",
    "    for batch_idx,(data,_) in enumerate(train_loader):\n",
    "        \n",
    "        data = Variable(data)\n",
    "        \n",
    "        compact_image = comCNN(data.cuda())\n",
    "        compact_image_temp = compact_image.cpu().detach()\n",
    "        compressed_image_btc = codec.BlockTruncationCoding(compact_image_temp)\n",
    "        upscaled_image_btc = codec.Interpolate(compressed_image_btc)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # update beta with eq 5\n",
    "    \n",
    "        recCNNOptimizer.zero_grad()\n",
    "        reconstructed_image,residual = recCNN(upscaled_image_btc.cuda())\n",
    "        loss2 = loss_function_l2(\n",
    "            residual_image=residual,\n",
    "            decoded_image=upscaled_image_btc.cuda(),\n",
    "            original_image=data.cuda()\n",
    "        )\n",
    "        loss2.backward()\n",
    "        \n",
    "        train_loss_2 += loss2.item()\n",
    "        recCNNOptimizer.step()\n",
    "    \n",
    "    \n",
    "        comCNNOptimizer.zero_grad()\n",
    "        upscaled_image_nonbtc = codec.Interpolate(compact_image)\n",
    "        reconstructed_without_btc,_ = recCNN(upscaled_image_nonbtc.cuda())\n",
    "        loss1 = loss_function_l1(\n",
    "            reconstructed_image=reconstructed_without_btc.cuda(),\n",
    "            original_image=data.cuda()\n",
    "        )\n",
    "        loss1.backward()\n",
    "        train_loss_1 += loss1.item()\n",
    "        comCNNOptimizer.step()\n",
    "        # print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} - {:.6f}'.format(\n",
    "        #         epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        #         100. * batch_idx / len(train_loader),\n",
    "        #         loss1.item() / len(data) , loss2.item()/len(data)))\n",
    "    end = time.time()\n",
    "    graph_l1[epoch] = train_loss_1/len(train_loader.dataset)\n",
    "    graph_l2[epoch] = train_loss_2/len(train_loader.dataset)\n",
    "    print('====> Epoch: {}\\nAverage loss 1: {:.4f}\\nAverage Loss 2: {:.4f}\\nRunning Time : {}'.format(\n",
    "          epoch, train_loss_1/len(train_loader.dataset),train_loss_2/len(train_loader.dataset),(end-start)))\n",
    "\n",
    "global_end = time.time()\n",
    "print(\"\\n========>Training Complete....\")\n",
    "print('Total Running Time : {}'.format((global_end-global_start)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Train\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.plot(graph_l1)\n",
    "plt.title(\"MSE L1\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(graph_l2)\n",
    "plt.title('MSE L2')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25,\n",
    "                    wspace=0.35)\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}